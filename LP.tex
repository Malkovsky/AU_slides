\documentclass[10pt]{beamer}
\usetheme{Madrid}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[OT1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\author{Мальковский Н.}
\title[Линейное программирование]{Линейное программирование}
%\setbeamercovered{transparent} 
\setbeamertemplate{navigation symbols}{} 
%\logo{} 
\institute[СПбГУ]{Санкт-Петербургский Государственный Университет}
\date{} 
%\subject{} 
\DeclareMathOperator*{\argmin}{argmin}


\newtheorem{theorem_ru}{Теорема}[]
\newtheorem{lemma_ru}{Лемма}[]
\newtheorem{corollary_ru}{Следствие}[]

\graphicspath{{image/}}
\newcommand{\Ima}{\text{Im}}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

\begin{frame}{Историческая справка}
\begin{itemize}
\item Линейное программирование появилось в 1930х-1940х годах. Является одним из первых обширных приложений математических методов в промышленном производстве.
\item Основателями линейного программирования считаются Д. Данциг (США) и Л. В. Канторович (СССР), несмотря на то, что, насколько известно автору, они никогда не встречались лично.
\item Канторович получил нобелевскую по экономике 1975г. за ``за вклад в теорию оптимального распределения ресурсов''. Симплекс-метод для решения задач линейного программирования (введен Данцигом) признан одним из 10 наиболее значимых алгоритмов 20 века обществом индустриальной и прикладной математики (SIAM).
\end{itemize}
\end{frame}

\begin{frame}{Общая задача ЛП}
Задачей \textit{линейного программирования} называется задача математической оптимизаций, в которой основной функционал и функции ограничений линейные. Более формально, пусть $c\in\mathbb{R}^n,~b\in\mathbb{R}^m,~d\in\mathbb{R}^k$, $A,~P$ -- матрицы размеров $m\times n$ и $k\times n$ соответственно, общая задача линейного программирования имеет вид
$$
\begin{array}{ll}
\mbox{минимизировать } & c^Tx \\ 
\mbox{при условии }    & Ax\leq b\\
& Px=d.
\end{array}
$$
По разным причинам, такая форма постановки задачи не очень удобна, обычно задачу приводят в стандартную форму:
$$
\begin{array}{ll}
\mbox{минимизировать } & c^Tx \\ 
\mbox{при условии }    & Ax=b\\
& x\geq 0_n.
\end{array}
$$

\end{frame}


\begin{frame}{3 приема приведения линейных форм}
\begin{enumerate}
\item Разбиение переменной на положительную и отрицательную компоненты, позволяет ввести неравенство для переменной, на которую нет ограничений
$$
x_i=x^+_i-x^-_i,~ x^+_i\geq 0, x^-_i\geq 0.
$$
\item Дополняющие переменные (\textit{slack variables})
$$
Ax\leq b~\Leftrightarrow~Ax+s=b,~s\geq 0_n.
$$
\item Представление неравенства в виде двух равенств
$$
Ax=b~\Leftrightarrow~Ax\geq b,~Ax\leq b.
$$
\end{enumerate}
Для приведения общей задачи в стандартную форму достаточно первых двух.
\end{frame}

\begin{frame}{Приведение в стандартную форму}
Пусть дана общая задача ЛП
$$
\begin{array}{ll}
\mbox{минимизировать } & c^Tx \\ 
\mbox{при условии }    & Ax\leq b\\
& Px=d.
\end{array}
$$
Введем дополняющие переменные $s=b-Ax$, таким образом $s\geq 0_m$. Далее, пусть $x=x^+-x^-,~x^+\geq 0_n,~x^-\geq 0_n$, в матричной форме
$$
x=[I_m~~-I_m]\left[\begin{array}{ll}
x^+ \\ x^-\end{array}\right].
$$
Таким образом общая задача переписывается в виде
$$
\begin{array}{ll}
\mbox{минимизировать } & c^T [I_m~~-I_m]\left[\begin{array}{ll}
x^+ \\ x^-\end{array}\right] \\ 
\mbox{при условии } & \left[
\begin{array}{ll} A \\ P \end{array}\right][I_m~~-I_m]\left[\begin{array}{ll}
x^+ \\ x^-\end{array}\right] + \left[\begin{array}{ll}
s \\ 0_k
\end{array}\right] = \left[\begin{array}{ll}
b \\ d
\end{array}\right] \\
& \left[\begin{array}{ll}
s \\ x^+ \\ x^-
\end{array}\right]=0_{2n+m}.
\end{array}
$$\end{frame}

\begin{frame}{Приведение в стандартную форму}
Обозначив
$$
\tilde{x}=\left[\begin{array}{ll}
s \\ x^+ \\ x^-
\end{array}\right]
$$
и
$$
\tilde{A}=\left[\begin{array}{ll}
A & -P \\
0 & 0.
\end{array}\right],~
\tilde{c}=\left[\begin{array}{ll}
0 \\
\mathbf{1}_n \\
-\mathbf{1}_n
\end{array}\right],~
\tilde{b}=\left[\begin{array}{ll}
b \\
d.
\end{array}\right]~
$$
получаем сведение общей задачи ЛП к стандартной форме
$$
\begin{array}{ll}
\mbox{минимизировать } & \tilde{c}^T\tilde{x} \\ 
\mbox{при условии }    & \tilde{A}\tilde{x}=\tilde{b}\\
& \tilde{x}\geq 0_{2n+m}.
\end{array}
$$
\end{frame}


\begin{frame}{Двойственность в задачах линейного программирования}
Пусть, $A$ -- матрица размера $m\times n$, $c\in \mathbb{R}^n, b\in \mathbb{R}^m$. Рассмотрим задачу линейного программирования в стандартной форме 
$$
\begin{array}{ll}
\mbox{минимизировать } & c^Tx\\
\mbox{при условии }    &  Ax= b\\
					   & x\geq 0_n.
\end{array}
$$
Лагранжиан:
$$
L(x, \lambda, \mu)= c^Tx-\lambda^Tx+\mu^T(Ax-b).
$$
Так как лагранжиан линеен по $x$, то двойственная функция отлична от $-\infty$ только если $c-\lambda+A^T\mu=0_n$, таким образом
$$
q(\lambda, \mu)=\left\{
\begin{array}{ll}
-\mu^Tb, &~c-\lambda+A^T\mu=0_n\\
-\infty, &~\mbox{в противном случае}.
\end{array}\right.
$$
Двойственная задача:
$$
\begin{array}{ll}
\mbox{максимизировать } & -\mu^Tb \\
\mbox{при условии }     & A^T\mu+c-\lambda=0_n \\
 & \lambda\geq 0_m. 
\end{array}
$$
\end{frame}

\begin{frame}{Двойственность в задачах линейного программирования}
В двойственной задаче можно избавиться от переменных $\lambda$ и получить следующую переформулировку
$$
\begin{array}{ll}
\mbox{максимизировать } & -\mu^Tb \\
\mbox{при условии }     & A^T\mu+c\geq 0_n. \\ 
\end{array}
$$
Если прямая задача разрешима, то для нее выполняется сильная двойственность. Это можно легко проверить с помощью условий ККТ:
\begin{align*}
c+A^T\mu-\lambda=0_n\\
Ax=b,~x\geq 0_n\\
\lambda\geq 0_m\\
\lambda_ix_i=0.
\end{align*}
Последовательно применяя прямую выполнимость и дополняющую нежесткость к стационарности получаем
$$
0_n=c^Tx+\mu^TAx-\lambda^Tx=c^Tx+\mu^Tb-\lambda^Tx=c^Tx+\mu^Tb~\Leftrightarrow~c^Tx=\mu^Tb.
$$

\end{frame}

\begin{frame}{Экономический смысл множителей Лагранжа}
Рассмотрим задача ЛП
$$
\begin{array}{ll}
\mbox{максимизировать } & c^Tx\\
\mbox{при условии }    & Ax\leq b\\
					   & x\geq 0_n.
\end{array}
$$
Легко проверить, что двойственной к этой задаче является следующая

$$
\begin{array}{ll}
\mbox{минимизировать } & \lambda^Tb\\
\mbox{при условии }    & \lambda^TA\geq c^T\\
					   & \lambda\geq 0_m.
\end{array}
$$
\end{frame}

\begin{frame}{Экономическая интерпретация множителей Лагранжа}
\begin{itemize}
\item
Предположим, что есть $n$ ресурсов, которые добываются из $m$ типов сырья. Из единицы сырья  $i$ можно получить $A_{i1}$ единиц первого ресурса, $A_{i2}$ единиц второго, $\ldots$, $A_{in}$ единиц $n$-ого.
\item Допустим, ежедневно потребляется $с_i$ единиц $i$-ого ресурса.
\item $b_i$ -- цена добычи единицы $i$-ого сырья.
\item В какой пропорции следует добывать сырьё, чтобы удовлетворить потребности ресурсов и минимизировать затраты?
\item Записав формально эту задачу получается в точности вторая задача с предыдущего слайда.
\item Посмотрим на ограничение соответствующей двойственной задачи:
$$
A_{i1}x_1+A_{i2}x_2+\ldots+A_{in}x_n\leq b_i.
$$
\item Если посмотреть на ``размерность'', то справа мы имеем стоимость добычи единицы сырья, а слева $[x_i]$ * (единиц ресурса в единице сырья). Таким образом $x_i$ -- стоимость добычи единицы ресурса.
\end{itemize}
\end{frame}

\begin{frame}{Матричные игры}
Самая простая форма матричной игры для двух игроков имеет следующий вид: игрок 1 имеет $n$ возможных действий (чистых стратегий), игрок 2 имеет $m$ возможных действий. Игроки ходят одновременно, т.е. предполагается, что оба игрока не знают стратегий оппонента. Матрица выплат $P$ размера $n\times m$ содержит информацию о результате игры: $P_{ij}$ -- сколько игрок 1 должен выплатить игроку 2 в случае, когда 1 выбирает чистую стратегию $i$, 2 выбирает чистую стратегию $j$ (если $P_{ij}<0$, то 2ой игрок платит первому). 
\vspace{2em}

Может ли в такой игре существовать ``оптимальная стратегия?''  
\end{frame}

\begin{frame}{Матричные игры}
Классический пример: камень-ножницы-бумага. У каждого игрока есть три варианта действий. Если игроки выбирают одинаковый вариант, то объявляется ничья. В противном случае выплачивает проигравший по правилу: камень бьет ножницы, ножницы бьют бумагу, бумага бьет камень. Матрица игры имеет следующий вид
$$
\left(
\begin{array}{lll}
0 & 1 & -1 \\
-1 & 0 & 1 \\
1 & -1 & 0
\end{array}
\right)
$$
Теперь предположим, что первый игрок имеет возможность узнать стратегию второго. В этом случае первый игрок может гарантировать себе победу. С другой стороны, тоже справедливо и для второго игрока.
\end{frame}

\begin{frame}{Матричные игры}
В общем случае, положим, что игроки играют так, будто их противники знают их стратегии и отвечают наилучшим для себя образом. Другими словами, первый игрок пытается минимизировать по $i$
$$
\max_jP_{ij},
$$
а второй игрок пытается максимизировать по $j$
$$
\min_iP_{ij}.
$$
Заметим, что всегда выполняется равенство $\max_j\min_iP_{ij}\leq \min_i\max_jP_{ij}$, как было отмечено на предыдущем слайде, неравенство может быть строгим.
\end{frame}

\begin{frame}{Матричные игры}
Вместо того, чтобы действовать детерминированно, можно выбирать действие случайно. Пусть $v\in\mathbb{R}^n, \mathbf{1}^T_nv=1$, $u\in\mathbb{R}^m, \mathbf{1}^T_mu=1$. $v_i$ -- вероятность того, что игрок 1 выберет действие $i$, аналогично $u_i$ -- вероятность того, что игрок 2 выберет действие $i$. $u, v$ обычно называются \textit{смешанными стратегиями}. Математическое ожидание проигрыша первого игрока есть
$$
v^TPu.
$$
Если игроки выбирает стратегию, чтобы минимизировать худший исход (используя смешанные стратегии), то первый игрок пытается выбрать стратегию $v$, которая минимизирует худший исход, равный
$$
\sup \{v^TPu~|~u\geq 0_m, \mathbf{1}_m^Tu=1\}=\max_i(P^Tv)_i.
$$
Аналогично, стратегия $u$ второго игрока:
$$
\inf \{v^TPu~|~v\geq 0_n, \mathbf{1}_n^Tv=1\}=\min_i(Pu)_i.
$$
\end{frame}

\begin{frame}{Матричные игры}
Лучшая стратегия для худшего случая первого игрока:
$$
\begin{array}{ll}
\mbox{минимизировать } & \max_i(P^Tv)_i\\
\mbox{при условии }    & \mathbf{1}^T_nv=1\\
 & v\geq 0_n.
\end{array}
$$
Лучшая стратегия для худшего случая второго игрока:
$$
\begin{array}{ll}
\mbox{максимизировать } & \min_i(Pu)_i\\
\mbox{при условии }    & \mathbf{1}^T_mu=1\\
 & u\geq 0_m.
\end{array}
$$
Оказывается, что решение обоих задач совпадает. 
\end{frame}

\begin{frame}{Матричные игры}
Преобразуем оптимизационную задачу для первого игрока введя дополнительную переменную $t$
$$
\begin{array}{ll}
\mbox{минимизировать } & t \\
\mbox{при условии }    & \mathbf{1}^T_nv=1 \\
 & P^Tv\leq t\mathbf{1}_m \\
 & v\geq 0_n.
\end{array}
$$
Лагранжиан:
$$
L(v, t, \lambda, \mu, s)=t+\lambda(\mathbf{1}^T_nv-1)+\mu^T(P^Tv-t\mathbf{1}_m)-s^Tv=
$$
$$
-\lambda+(P\mu+\lambda\mathbf{1}_n-s)^Tv+(1-\mathbf{1}^T_m\mu)t.
$$
Двойственная задача:
$$
\begin{array}{ll}
\mbox{максимизировать } & -\lambda \\
\mbox{при условии }    & \mathbf{1}^T_m\mu=1 \\
 & P\mu\geq -\lambda\mathbf{1}_n \\
 & \mu\geq 0_m,
\end{array}
$$
что и является задачей оптимизации для второго игрока.
\end{frame}

\begin{frame}{Матричные игры}
Итог:\\
\begin{itemize}
\item Для любой матричной игры существует пара смешанных стратегий $(v^*, u^*)$ таких, что ни один игрок не может улучшить свой выигрыш, выбрав другую стратегию, если при этом его оппонент играет той же стратегией. Иначе говоря
$$
\max_u {v^*}^TPu={v^*}^TPu^*=\min_v v^TPu^*.
$$
Такую пару стратегий принято называть \textit{равновесием Нэша}.
\end{itemize}
\end{frame}


\begin{frame}{Задача о назначениях}
Задача о назначениях -- одна из классических задач оптимизации, являющаяся частным случаем целочисленной задачи ЛП.\\
Исходная постановка имеет следующий вид: дана матрица $С=(c_{ij})$ размера $n\times n$ с неотрицательными элементами. Требуется найти такую перестановку $p$ порядка $n$, которая минимизирует 
$$
\sum_{i=1}^nC_{ip_i}.
$$
\end{frame}

\begin{frame}{Задача о назначениях}
Задачу можно переформулировать в терминах ЛП следующим образом
$$
\begin{array}{ll}
\mbox{минимизировать } & \sum_{i,j=1}^nc_{ij}x_{ij},\\
\mbox{при условии }    & \sum_{i=1}^nx_{ij}=1,\\
					   & \sum_{j=1}^nx_{ij}=1,\\
					   & x_{ij}\geq 0.
\end{array}
$$
$x_{ij}$ обозначает, берем ли мы элемент $ij$ или не берем. Можно показать что не имеет значение, ограничиваем ли мы значения $x_{ij}$ только до $\{0,1\}$.\\
Двойственная задача:
$$
\begin{array}{ll}
\mbox{максимизировать } & \sum_{i=1}^nu_i+v_i,\\
\mbox{при условии }    & u_i+v_j\leq c_{ij}.
\end{array}
$$
Дополняющая нежесткость: $x_{ij}(c_{ij}-u_i+v_j)=0$.
\end{frame}

\begin{frame}{Задача о назначениях}
Таким образом, если $x$ -- оптимальное решение, то существует пара векторов $u$ и $v$, такие что
$$
u_i+v_j\leq c_{ij},
$$
$$
x_{ij}>0\Rightarrow (u_i+v_j)=c_{ij}.
$$
Теперь предположим, что мы зафиксировали пару $(u,v)$ и пытаемся найти $x$ такое, чтобы выполнялись прямые ограничения. Такая задача эквивалента относительно простому нахождению максимального паросочетания в двудольном графе.
\vspace{2em}

Эта идея является основой так называемого Венгерского алгоритма. Этот метод итеративно обновляет $(u,v)$ и находит максимальное паросочетание на каждой итерации. Алгоритм завершается когда выполняется дополняющая нежесткость. В общем смысле алгоритмы такого типа называются \textit{прямо-двойственными} (\textit{англ.} primal-dual). 
\end{frame}

\begin{frame}{Задача о максимальном потоке}
Пусть $G=\langle V, E\rangle$ -- ориентированный граф, $|V|=n$, $|E|=m$. Для простоты считаем, что вершины и ребра пронумерованы первыми $n$ и $m$ натуральными числами соответственно. Пусть $B$ -- матрица инцидентности
$$
B_{ie}=\left\{
\begin{array}{ll}
-1, & \mbox{e выходит из i} \\
1, & \mbox{e входит в i} \\ 
0, & \mbox{в остальных случаях}.
\end{array}\right.
$$
Пусть в графе выделены две вершины $s,t$ -- исток и сток соответственно. Обозначим $\chi^{st}:~\chi^{st}_s=-1,~\chi^{st}_t=1,~\chi^{st}_i=0$. Задачей о максимальном потоке называется следующая задача линейного программирования:
$$
\begin{array}{ll}
\mbox{максимизировать } & v \\ 
\mbox{при условии }     & Bf=v\chi^{st}\\
 & 0_m\leq f\leq c,
\end{array}
$$
где $c_i$ -- пропускная способность дуги $i$, $f_i$ -- поток по дуге $i$. Ограничение $Bf=v\chi^{st}$ означает, что для каждой промежуточной вершины объем входящего потока равен объему исходящего потока, а для вершин $s,t$ разница составляет $v$. Другими словами, из истока исходит поток $v$ и входит в сток $t$. Величину потока $v$ мы хотим максимизировать.
\end{frame}

\begin{frame}{Задача о максимальном потоке}
Сопоставим вектор $p$ ограничению $Bf=v\chi^{st}$, $\lambda$ -- ограничению $f\leq c$, $\mu$ -- ограничению $0_m\leq f$. Лагранжиан для задачи о максимальном потоке:
$$
L(x, v, \lambda, \mu, p)=v+p^T(Bf-v\chi^{st})-\lambda^T(f-c)+\mu^Tf.
$$
Двойственная выполнимость: $\lambda, \mu\geq 0_m$.\\
Для простоты записи, считаем, что величины $c_{ij}, f_{ij}, \lambda_{ij}, \mu_{ij}$ соответствуют дуге, исходящей из $i$ и входящей в $j$. Стационарность:
$$
\frac{\partial}{\partial f_{ij}}L(f, v, \lambda, \mu, p)=p_j-p_i-\lambda_{ij}+\mu_{ij},
$$
$$
\frac{\partial}{\partial v}L(f, v, \lambda, \mu, p)=1-p_t+p_s.
$$
Дополняющая нежесткость:
$$
\mu_{ij}f_{ij}=0,~\lambda_{ij}(f_{ij}-c_{ij})=0.
$$
\end{frame}

\begin{frame}{Задача о максимальном потоке}
От переменных $\lambda_{ij}, \mu_{ij}$ можно избавиться: подставляя дополняющую нежесткость и двойственную выполнимость в  стационарность получаем
$$
\left\{\begin{array}{ll}
f_{ij}>0~\Rightarrow~p_j\geq p_i \\
f_{ij}<c_{ij}~\Rightarrow~p_j\leq p_i
\end{array}\right.
$$
Обозначим $E'=\{(i,j)\in E~|~f_{ij}<c_{ij}\}\cup\{(j, i)~|~(i,j)\in E, f_{ij}>0\}$. $E'$ принято называть \textit{остаточной сетью}. Из ранее выведенных соотношений, если $(i,j)\in E'$, то $p_i\geq p_j$. 

Наконец, для выполнимости $p_t=p_s+1$ необходимо и достаточно, чтобы в дополняющей сети не было пути из истока в сток. Если такой путь существует (обозначим его за $s\rightarrow v_1\rightarrow v_2 \rightarrow \ldots \rightarrow v_k \rightarrow t$), то 
$$
p_s\geq p_{v_1}\geq \ldots \geq p_{v_k}\geq p_t\neq p_s+1>p_s.
$$
Если же такого пути нет, то достаточно взять $p_v=0$ для вершин, достижимых из $s$ по ребрам остаточной сети, $p_v=1$ для всех остальных.
\end{frame}

\begin{frame}{Задача о максимальном потоке}
Теперь посмотрим на двойственную задачу:
$$
\begin{array}{ll}
\mbox{минимизировать } & \lambda^Tc \\
\mbox{при условии }    & B^Tp-\lambda\leq 0_m \\
 & p_t=p_s+1 \\
 & \lambda \geq 0.
\end{array}
$$
В этой задачи мы сразу избавились от переменных $\mu$, так как они выполняют дополняющую роль. Условие $B^Tp-\lambda\leq 0_m$ соответствует уже полученному ранее $p_j-p_i-\lambda_{ij}\leq 0$. Можно показать, что $\lambda_i$ и $p_i$ можно искать только среди множества $\{0,1\}$. В этом случае задача заключается в нахождении такого множества дуг $A\subset E$, которое покрывает все пути из $s$ в $t$ и при этом имеет минимальную суммарную пропускную способность. Это в точность \textit{задача о минимальном разрезе}.
\end{frame}

\begin{frame}{Теорема о декомпозиции потока}
\begin{theorem_ru}
Пусть $G=\langle V, E\rangle$ -- ориентированный граф с выделенными вершинами $s,t$, $0_m\leq f\in \mathbb{R}^n$ -- поток, удовлетворяющий $Bf=v\chi^{st}$ для некоторого скаляра $v\geq 0$, тогда существует разбиение потока $f=f^1+f^2+\ldots+f^k$, $k\leq m$ такое, что $f^i$ является потоком и при этом выполняется одно из двух
\begin{itemize}
\item Компоненты $f^i$ отличны только вдоль некоторого цикла.
\item Компоненты $f^i$ отличны от нуля только вдоль некоторого пути из $s$ в $t$.
\end{itemize}
\end{theorem_ru}
\textbf{Док-во.} Если $v=0$, то разбиение тривиально. Пусть $v>0$. 
\begin{itemize}
\item
Начнем двигаться (в глубину) из $s$ по дугам, для которых $f_i$ пока либо не придем в $t$, либо не придем в вершину, которую мы посетили ранее. 
\item Пусть $E_1=e_1, \ldots, e_l$ -- набор дуг либо на получившемся цикле, либо на получившемся пути.
\item Положим $f^1:~f^1_i=\min_{e\in E_1}f_e,~i\in E_1$, $f^1_i=0,~e\notin E_1$.
\item Повторим процедуру для $f-f^1$. Заметим, что $|\{e\in E~|~f_e-f^1_e>0\}|\leq|\{e\in E~|~f_e>0\}|-1$, следовательно процедура завершится не более чем за $m$ итераций.
\end{itemize}
\end{frame}

\begin{frame}{Задача о кратчайших расстояниях}
Положим у нас есть положительные веса $\sigma_e$ для каждой дуги $e$, мы хотим пропустить единичный поток из $s$ в $t$ без ограничений на пропускные способности, при этом минимизируя $\sigma^Tf$. Другими словами, пытаемся решать задачу
$$
\begin{array}{ll}
\mbox{минимизировать } & \sigma^Tf \\
\mbox{при условии }    & Bf=\chi^{st} \\
 & 0_m\leq f.
\end{array}
$$
Не трудно показать, что оптимальное значение для этой задачи в точности соответствует кратчайшему расстоянию от $s$ до $t$, при этом поток может быть положителен только для дуг, которые лежат на некотором кратчайшем пути. В чем же заключается двойственная задача? Лагранжиан:
$$
L(f, p, \mu)=\sigma^Tf+p^T(Bf-\chi^{st})-\mu^Tf.
$$
Стационарность:
$$
\frac{\partial}{\partial f_{ij}}L(f,p,\mu)=\sigma_{ij}+p_j-p_i-\mu_{ij}.
$$
\end{frame}

\begin{frame}{Задача о кратчайшем пути}
Дополняющая нежесткость:
$$
f_{ij}\mu_{ij}=0.
$$
Таким образом, если $f_{ij}>0$, то $p_i-p_j=\sigma_{ij}$, из чего и следует что поток течет по кратчайшим путям.\\ 
Двойственная задача:
$$
\begin{array}{ll}
\mbox{максимизировать } & p_s-p_t \\
\mbox{при условии }    & p_i-p_j\leq \sigma_{ij}.
\end{array}
$$
\end{frame}

\begin{frame}{Задача о кратчайшем пути}
Двойственную задачу можно интерпретировать следующим образом: предположим, что вершины графа -- очень маленькие частицы, соединенные нитками соответствующей длины. Если потянуть в противоположные стороны вершины $s,t$, то нити, лежащие на кратчайших путях от $s$ в $t$, натянутся. Максимальное расстояние, на которое такое растяжение возможно -- кратчайшее расстояние между $s$ и $t$.\\
\begin{center}
\includegraphics[width=.7\textwidth,trim=1cm 1cm 1cm 0cm]{ST_graph}
\end{center}
\end{frame}


\end{document}